{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665f422c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ba9afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory where the text files are located\n",
    "songs_dir = \"songs\"\n",
    "data = []\n",
    "# Loop through each file in the directory\n",
    "for root, dirs, files in os.walk(songs_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            artist = os.path.basename(root)\n",
    "            with open(os.path.join(root, file), 'r', encoding=\"utf8\") as f:\n",
    "                lyrics = f.read().replace('\\n', ' ')\n",
    "                # Add the data to the DataFrame\n",
    "                data.append([artist, lyrics])\n",
    "                \n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(data, columns=['Artist', 'Lyrics'])\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('lyrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6965f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"lyrics.csv\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create a list of stopwords to remove\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\"verse\")\n",
    "stop_words.add(\"intro\")\n",
    "\n",
    "# Create a stemmer to use for word stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess each lyric in the DataFrame\n",
    "for i, row in data.iterrows():\n",
    "#Convert the lyric to lowercase\n",
    "    lyric = str(row[\"Lyrics\"]).lower()\n",
    "    match = re.search(r'lyrics\\[[^\\]]*\\]', lyric)\n",
    "\n",
    "    # Check if the split was successful\n",
    "    if match:\n",
    "        split_index = match.end()\n",
    "        cleaned_lyric = lyric[split_index:]\n",
    "    else:\n",
    "        cleaned_lyric = lyric\n",
    "\n",
    "    #Tokenize the lyric into words\n",
    "    words = word_tokenize(cleaned_lyric)\n",
    "\n",
    "    #Remove stop words and punctuation\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    #Stem each word\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    #Join the stemmed words back into a single string\n",
    "    preprocessed_lyric = \" \".join(stemmed_words)\n",
    "\n",
    "    #Replace the original lyric with the preprocessed lyric in the DataFrame\n",
    "    data.at[i, \"Lyrics\"] = preprocessed_lyric\n",
    "\n",
    "# Export the preprocessed DataFrame to a CSV file\n",
    "data.to_csv(\"preprocessed_lyrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab54ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "pre_processed_data = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(pre_processed_data[\"Lyrics\"])\n",
    "sequences = tokenizer.texts_to_sequences(pre_processed_data[\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e5abb47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m artist_data \u001b[39m=\u001b[39m pre_processed_data[pre_processed_data[\u001b[39m\"\u001b[39m\u001b[39mArtist\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m artist]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Split the artist data into training, validation, and testing sets\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m artist_train, artist_test \u001b[39m=\u001b[39m train_test_split(artist_data, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m artist_train, artist_val \u001b[39m=\u001b[39m train_test_split(artist_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/lyricgenerator_deeplearning/lyricgenerator.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Concatenate the artist training, validation, and testing dataframes with the overall training, validation, and testing dataframes\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   2564\u001b[0m )\n\u001b[1;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2240\u001b[0m     )\n\u001b[1;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#For Artist Classification\n",
    "\n",
    "artists = pre_processed_data[\"Artist\"].unique()\n",
    "# Encode the artist names as integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "pre_processed_data[\"Artist\"] = label_encoder.fit_transform(pre_processed_data[\"Artist\"])\n",
    "\n",
    "# Initialize empty dataframes for training, validation, and testing\n",
    "train_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "val_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "test_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "\n",
    "for artist in artists:\n",
    "    # Get the data for the current artist\n",
    "    artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "    \n",
    "    # Split the artist data into training, validation, and testing sets\n",
    "    artist_train, artist_test = train_test_split(artist_data, test_size=0.2, random_state=42)\n",
    "    artist_train, artist_val = train_test_split(artist_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Concatenate the artist training, validation, and testing dataframes with the overall training, validation, and testing dataframes\n",
    "    train_df = pd.concat([train_df, artist_train])\n",
    "    val_df = pd.concat([val_df, artist_val])\n",
    "    test_df = pd.concat([test_df, artist_test])\n",
    "\n",
    "# Create a directory to store the CSV files\n",
    "directory = \"data_splits\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n",
    "\n",
    "train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de02e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train = pd.read_csv('data_splits/train.csv')\n",
    "val = pd.read_csv('data_splits/val.csv')\n",
    "test = pd.read_csv('data_splits/test.csv')\n",
    "\n",
    "#Creation of MLP model:\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_mlp.add(GlobalMaxPooling1D())\n",
    "model_mlp.add(Dense(100, activation='relu'))\n",
    "model_mlp.add(Dropout(0.4))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(8, activation='softmax'))\n",
    "\n",
    "tokenizer.fit_on_texts(train['Lyrics'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train['Lyrics'])\n",
    "sequences_val = tokenizer.texts_to_sequences(val['Lyrics'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test['Lyrics'])\n",
    "word_index = tokenizer.word_index\n",
    "X_train = pad_sequences(sequences_train, maxlen=200)\n",
    "X_val = pad_sequences(sequences_val, maxlen=200)\n",
    "X_test = pad_sequences(sequences_test, maxlen=200)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(train['Artist'])\n",
    "y_val = to_categorical(val['Artist'])\n",
    "y_test = to_categorical(test['Artist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f076bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply earlystopping in order to avoid over-fitting\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e35714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 145ms/step - loss: 2.0779 - accuracy: 0.1250 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.0800 - accuracy: 0.1211 - val_loss: 2.0795 - val_accuracy: 0.1250\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0780 - accuracy: 0.1328 - val_loss: 2.0793 - val_accuracy: 0.1250\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.0762 - accuracy: 0.1289 - val_loss: 2.0789 - val_accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.0833 - accuracy: 0.0977 - val_loss: 2.0782 - val_accuracy: 0.1250\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0861 - accuracy: 0.1055 - val_loss: 2.0779 - val_accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.0856 - accuracy: 0.1094 - val_loss: 2.0773 - val_accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.0777 - accuracy: 0.1484 - val_loss: 2.0769 - val_accuracy: 0.1250\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.0791 - accuracy: 0.1250 - val_loss: 2.0763 - val_accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0767 - accuracy: 0.1367 - val_loss: 2.0757 - val_accuracy: 0.1562\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.0807 - accuracy: 0.1172 - val_loss: 2.0751 - val_accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.0725 - accuracy: 0.1562 - val_loss: 2.0740 - val_accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.0793 - accuracy: 0.1211 - val_loss: 2.0725 - val_accuracy: 0.2188\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.0669 - accuracy: 0.1758 - val_loss: 2.0709 - val_accuracy: 0.2344\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.0585 - accuracy: 0.1719 - val_loss: 2.0690 - val_accuracy: 0.2188\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0531 - accuracy: 0.1992 - val_loss: 2.0670 - val_accuracy: 0.1875\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0614 - accuracy: 0.1562 - val_loss: 2.0642 - val_accuracy: 0.2188\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 2.0586 - accuracy: 0.2227 - val_loss: 2.0602 - val_accuracy: 0.4219\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0379 - accuracy: 0.1836 - val_loss: 2.0542 - val_accuracy: 0.4062\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0392 - accuracy: 0.1875 - val_loss: 2.0481 - val_accuracy: 0.3125\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.0238 - accuracy: 0.2539 - val_loss: 2.0403 - val_accuracy: 0.3125\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.0005 - accuracy: 0.2656 - val_loss: 2.0269 - val_accuracy: 0.3906\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0032 - accuracy: 0.2539 - val_loss: 2.0118 - val_accuracy: 0.2969\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 1.9805 - accuracy: 0.2383 - val_loss: 1.9899 - val_accuracy: 0.3125\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.9360 - accuracy: 0.3125 - val_loss: 1.9564 - val_accuracy: 0.4688\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.8619 - accuracy: 0.3555 - val_loss: 1.9142 - val_accuracy: 0.5156\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.7852 - accuracy: 0.3711 - val_loss: 1.8571 - val_accuracy: 0.3750\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.7346 - accuracy: 0.3789 - val_loss: 1.7771 - val_accuracy: 0.5938\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.6359 - accuracy: 0.3633 - val_loss: 1.6940 - val_accuracy: 0.5781\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.5354 - accuracy: 0.4219 - val_loss: 1.5995 - val_accuracy: 0.6094\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.4682 - accuracy: 0.4961 - val_loss: 1.5125 - val_accuracy: 0.5781\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.3971 - accuracy: 0.4492 - val_loss: 1.4347 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.2853 - accuracy: 0.5508 - val_loss: 1.3505 - val_accuracy: 0.5938\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.1753 - accuracy: 0.5469 - val_loss: 1.2652 - val_accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1671 - accuracy: 0.5039 - val_loss: 1.2005 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0370 - accuracy: 0.6094 - val_loss: 1.1476 - val_accuracy: 0.6562\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.9104 - accuracy: 0.6797 - val_loss: 1.0959 - val_accuracy: 0.6719\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.8853 - accuracy: 0.6875 - val_loss: 1.0524 - val_accuracy: 0.6719\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7547 - accuracy: 0.7461 - val_loss: 0.9913 - val_accuracy: 0.6094\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7635 - accuracy: 0.7070 - val_loss: 0.9625 - val_accuracy: 0.6562\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.6809 - accuracy: 0.7422 - val_loss: 0.9034 - val_accuracy: 0.6875\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.5877 - accuracy: 0.8164 - val_loss: 0.8650 - val_accuracy: 0.6719\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.5052 - accuracy: 0.8320 - val_loss: 0.8131 - val_accuracy: 0.6875\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5104 - accuracy: 0.8281 - val_loss: 0.8203 - val_accuracy: 0.6719\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4968 - accuracy: 0.8398 - val_loss: 0.7417 - val_accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.4244 - accuracy: 0.8633 - val_loss: 0.7546 - val_accuracy: 0.7656\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.4245 - accuracy: 0.8477 - val_loss: 0.7592 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3596 - accuracy: 0.8828 - val_loss: 0.7543 - val_accuracy: 0.7812\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3693 - accuracy: 0.8828 - val_loss: 0.7278 - val_accuracy: 0.7812\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3259 - accuracy: 0.8945 - val_loss: 0.7103 - val_accuracy: 0.7656\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2740 - accuracy: 0.9102 - val_loss: 0.7222 - val_accuracy: 0.7812\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2914 - accuracy: 0.9180 - val_loss: 0.6851 - val_accuracy: 0.7812\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2301 - accuracy: 0.9336 - val_loss: 0.6807 - val_accuracy: 0.7812\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2503 - accuracy: 0.9336 - val_loss: 0.6883 - val_accuracy: 0.7969\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1921 - accuracy: 0.9570 - val_loss: 0.6970 - val_accuracy: 0.7812\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.2299 - accuracy: 0.9258 - val_loss: 0.6946 - val_accuracy: 0.7812\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1788 - accuracy: 0.9492 - val_loss: 0.6933 - val_accuracy: 0.7969\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2081 - accuracy: 0.9219 - val_loss: 0.6786 - val_accuracy: 0.8281\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1656 - accuracy: 0.9453 - val_loss: 0.6966 - val_accuracy: 0.8125\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1319 - accuracy: 0.9609 - val_loss: 0.7839 - val_accuracy: 0.7656\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1559 - accuracy: 0.9609 - val_loss: 0.6855 - val_accuracy: 0.7969\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1546 - accuracy: 0.9570 - val_loss: 0.6518 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1351 - accuracy: 0.9531 - val_loss: 0.7027 - val_accuracy: 0.7812\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1227 - accuracy: 0.9688 - val_loss: 0.7002 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1632 - accuracy: 0.9375 - val_loss: 0.6876 - val_accuracy: 0.7812\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1063 - accuracy: 0.9766 - val_loss: 0.6752 - val_accuracy: 0.7969\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1054 - accuracy: 0.9648 - val_loss: 0.6995 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1643dcee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb8280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.7083 - accuracy: 0.7750 - 154ms/epoch - 51ms/step\n",
      "Test accuracy: 0.7749999761581421\n"
     ]
    }
   ],
   "source": [
    "#Testing our model's accuracy based on a separate test set. \"X and Y test\"\n",
    "test_loss, test_acc = model_mlp.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1b89ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "del model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8483ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 10:26:27.620764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 10:26:27.623155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 10:26:27.624484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 300)          2429400   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 128)          219648    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,781,664\n",
      "Trainable params: 2,781,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 10:26:27.837383: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 10:26:27.840335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 10:26:27.842433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(LSTM(128))\n",
    "model_lstm.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f44011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove unnecessary characters, symbols, or patterns\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text within square brackets\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)  # Remove text within parentheses\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words and punctuation\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Perform stemming on words if desired\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the words back into a single string\n",
    "    preprocessed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "009f3a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating lyrics for 4:\n",
      "4\n",
      "Generating lyrics for 6:\n",
      "6\n",
      "Generating lyrics for 5:\n",
      "5\n",
      "Generating lyrics for 3:\n",
      "3\n",
      "Generating lyrics for 2:\n",
      "2\n",
      "Generating lyrics for 0:\n",
      "0\n",
      "Generating lyrics for 1:\n",
      "1\n",
      "Generating lyrics for 7:\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "# Create a directory to store the generated lyrics\n",
    "generated_lyrics_dir = \"Generated Lyrics\"\n",
    "if not os.path.exists(generated_lyrics_dir):\n",
    "    os.makedirs(generated_lyrics_dir)\n",
    "\n",
    "# Set the maximum number of words to generate for each artist\n",
    "max_words = max_lines * max_line_length\n",
    "\n",
    "# Iterate through each artist\n",
    "for artist in artists:\n",
    "    print(f\"Generating lyrics for {artist}:\")\n",
    "    \n",
    "    # Convert the artist to a string\n",
    "    artist_str = str(artist)\n",
    "    print(artist)\n",
    "    \n",
    "    # # Filter the dataset for the current artist\n",
    "    # artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "    \n",
    "    # # Check if the artist has any lyrics\n",
    "    # if artist_data.empty:\n",
    "    #     print(\"No lyrics found for this artist.\")\n",
    "    #     continue\n",
    "    \n",
    "    # # Select a random seed text from the artist's lyrics\n",
    "    # seed_text = random.choice(artist_data[\"Lyrics\"])\n",
    "    \n",
    "    # # Convert the seed text to a sequence\n",
    "    # seed_sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    # seed_sequence = [x + 1 for x in seed_sequence]\n",
    "    \n",
    "    # # Pad the sequence to match the input length\n",
    "    # seed_sequence = pad_sequences([seed_sequence], maxlen=200)\n",
    "    \n",
    "    # # Generate lyrics\n",
    "    # generated_lyrics = seed_text\n",
    "    \n",
    "    # # Generate lyrics line by line\n",
    "    # lines_generated = 1\n",
    "    # current_line = \"\"\n",
    "    \n",
    "    # while lines_generated <= max_lines:\n",
    "    #     # Predict the probabilities for the next word\n",
    "    #     predictions = model_lstm.predict(seed_sequence)[0]\n",
    "        \n",
    "    #     # Sample the next word from the predicted probabilities\n",
    "    #     next_word_index = np.random.choice(len(predictions), p=predictions)\n",
    "    #     next_word = tokenizer.index_word[next_word_index + 1]\n",
    "        \n",
    "    #     # Check if the current line plus the next word exceeds the maximum line length\n",
    "    #     if len(current_line.split()) + len(next_word.split()) > max_line_length:\n",
    "    #         generated_lyrics += current_line + \"\\n\"\n",
    "    #         current_line = \"\"\n",
    "    #         lines_generated += 1\n",
    "        \n",
    "    #     # Append the next word to the current line\n",
    "    #     current_line += \" \" + next_word\n",
    "        \n",
    "    #     # Update the seed sequence for the next iteration\n",
    "    #     seed_sequence = np.roll(seed_sequence, -1)\n",
    "    #     seed_sequence[0][-1] = next_word_index\n",
    "    \n",
    "    # # Append the last line to the generated lyrics\n",
    "    # generated_lyrics += current_line + \"\\n\"\n",
    "    \n",
    "    # # Write the generated lyrics to a file for the current artist\n",
    "    # artist_lyrics_dir = os.path.join(generated_lyrics_dir, artist_str)\n",
    "    # if not os.path.exists(artist_lyrics_dir):\n",
    "    #     os.makedirs(artist_lyrics_dir)\n",
    "    \n",
    "    # file_name = os.path.join(artist_lyrics_dir, \"generated_lyrics.txt\")\n",
    "    # with open(file_name, \"w\") as f:\n",
    "    #     f.write(generated_lyrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c044e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a56ab0802a9f8dff423d90067d6d7134d68682fb43c017439decf42f84c36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
