{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665f422c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5ba9afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory where the text files are located\n",
    "songs_dir = \"songs\"\n",
    "data = []\n",
    "# Loop through each file in the directory\n",
    "for root, dirs, files in os.walk(songs_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            artist = os.path.basename(root)\n",
    "            with open(os.path.join(root, file), 'r', encoding=\"utf8\") as f:\n",
    "                lyrics = f.read().replace('\\n', ' ')\n",
    "                # Add the data to the DataFrame\n",
    "                data.append([artist, lyrics])\n",
    "                \n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(data, columns=['Artist', 'Lyrics'])\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('lyrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6965f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"lyrics.csv\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create a list of stopwords to remove\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\"verse\")\n",
    "stop_words.add(\"intro\")\n",
    "\n",
    "# Create a stemmer to use for word stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess each lyric in the DataFrame\n",
    "for i, row in data.iterrows():\n",
    "#Convert the lyric to lowercase\n",
    "    lyric = str(row[\"Lyrics\"]).lower()\n",
    "    match = re.search(r'lyrics\\[[^\\]]*\\]', lyric)\n",
    "\n",
    "    # Check if the split was successful\n",
    "    if match:\n",
    "        split_index = match.end()\n",
    "        cleaned_lyric = lyric[split_index:]\n",
    "    else:\n",
    "        cleaned_lyric = lyric\n",
    "\n",
    "    #Tokenize the lyric into words\n",
    "    words = word_tokenize(cleaned_lyric)\n",
    "\n",
    "    #Remove stop words and punctuation\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    #Stem each word\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    #Join the stemmed words back into a single string\n",
    "    preprocessed_lyric = \" \".join(stemmed_words)\n",
    "\n",
    "    #Replace the original lyric with the preprocessed lyric in the DataFrame\n",
    "    data.at[i, \"Lyrics\"] = preprocessed_lyric\n",
    "\n",
    "# Export the preprocessed DataFrame to a CSV file\n",
    "data.to_csv(\"preprocessed_lyrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2ab54ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "pre_processed_data = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(pre_processed_data[\"Lyrics\"])\n",
    "sequences = tokenizer.texts_to_sequences(pre_processed_data[\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3e5abb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#For Artist Classification\n",
    "\n",
    "artists = pre_processed_data[\"Artist\"].unique()\n",
    "# Encode the artist names as integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "pre_processed_data[\"Artist\"] = label_encoder.fit_transform(pre_processed_data[\"Artist\"])\n",
    "\n",
    "# Initialize empty dataframes for training, validation, and testing\n",
    "train_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "val_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "test_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "\n",
    "for artist in artists:\n",
    "    # Get the data for the current artist\n",
    "    artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "    \n",
    "    # Split the artist data into training, validation, and testing sets\n",
    "    artist_train, artist_test = train_test_split(artist_data, test_size=0.2, random_state=42)\n",
    "    artist_train, artist_val = train_test_split(artist_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Concatenate the artist training, validation, and testing dataframes with the overall training, validation, and testing dataframes\n",
    "    train_df = pd.concat([train_df, artist_train])\n",
    "    val_df = pd.concat([val_df, artist_val])\n",
    "    test_df = pd.concat([test_df, artist_test])\n",
    "\n",
    "# Create a directory to store the CSV files\n",
    "directory = \"data_splits\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n",
    "\n",
    "train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7de02e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train = pd.read_csv('data_splits/train.csv')\n",
    "val = pd.read_csv('data_splits/val.csv')\n",
    "test = pd.read_csv('data_splits/test.csv')\n",
    "\n",
    "#Creation of MLP model:\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_mlp.add(GlobalMaxPooling1D())\n",
    "model_mlp.add(Dense(100, activation='relu'))\n",
    "model_mlp.add(Dropout(0.4))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(8, activation='softmax'))\n",
    "\n",
    "tokenizer.fit_on_texts(train['Lyrics'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train['Lyrics'])\n",
    "sequences_val = tokenizer.texts_to_sequences(val['Lyrics'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test['Lyrics'])\n",
    "word_index = tokenizer.word_index\n",
    "X_train = pad_sequences(sequences_train, maxlen=200)\n",
    "X_val = pad_sequences(sequences_val, maxlen=200)\n",
    "X_test = pad_sequences(sequences_test, maxlen=200)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(train['Artist'])\n",
    "y_val = to_categorical(val['Artist'])\n",
    "y_test = to_categorical(test['Artist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f076bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply earlystopping in order to avoid over-fitting\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7e35714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 112ms/step - loss: 2.0845 - accuracy: 0.1250 - val_loss: 2.0798 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.0803 - accuracy: 0.1094 - val_loss: 2.0793 - val_accuracy: 0.1250\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0822 - accuracy: 0.1250 - val_loss: 2.0793 - val_accuracy: 0.1250\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0840 - accuracy: 0.1328 - val_loss: 2.0788 - val_accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.0775 - accuracy: 0.1289 - val_loss: 2.0786 - val_accuracy: 0.1250\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 2.0790 - accuracy: 0.1367 - val_loss: 2.0782 - val_accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0817 - accuracy: 0.1133 - val_loss: 2.0777 - val_accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0720 - accuracy: 0.1289 - val_loss: 2.0778 - val_accuracy: 0.1250\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.0796 - accuracy: 0.1289 - val_loss: 2.0779 - val_accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.0735 - accuracy: 0.1758 - val_loss: 2.0775 - val_accuracy: 0.1250\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.0812 - accuracy: 0.1172 - val_loss: 2.0768 - val_accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.0818 - accuracy: 0.1133 - val_loss: 2.0754 - val_accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.0713 - accuracy: 0.1328 - val_loss: 2.0738 - val_accuracy: 0.1250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0766 - accuracy: 0.1328 - val_loss: 2.0724 - val_accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.0626 - accuracy: 0.1602 - val_loss: 2.0710 - val_accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.0591 - accuracy: 0.1875 - val_loss: 2.0700 - val_accuracy: 0.1719\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.0655 - accuracy: 0.1602 - val_loss: 2.0673 - val_accuracy: 0.2500\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0592 - accuracy: 0.1680 - val_loss: 2.0631 - val_accuracy: 0.2031\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.0544 - accuracy: 0.1797 - val_loss: 2.0574 - val_accuracy: 0.3594\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.0366 - accuracy: 0.2539 - val_loss: 2.0522 - val_accuracy: 0.1406\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.0297 - accuracy: 0.2070 - val_loss: 2.0434 - val_accuracy: 0.2031\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.0099 - accuracy: 0.2734 - val_loss: 2.0320 - val_accuracy: 0.2812\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.9865 - accuracy: 0.2930 - val_loss: 2.0164 - val_accuracy: 0.2969\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1.9752 - accuracy: 0.2500 - val_loss: 1.9918 - val_accuracy: 0.2656\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.9290 - accuracy: 0.3633 - val_loss: 1.9589 - val_accuracy: 0.3281\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.8845 - accuracy: 0.3672 - val_loss: 1.9156 - val_accuracy: 0.3594\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.8273 - accuracy: 0.3555 - val_loss: 1.8574 - val_accuracy: 0.2969\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.7282 - accuracy: 0.4023 - val_loss: 1.7864 - val_accuracy: 0.3750\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.6342 - accuracy: 0.4688 - val_loss: 1.6944 - val_accuracy: 0.4062\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.5816 - accuracy: 0.4062 - val_loss: 1.5974 - val_accuracy: 0.4531\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.4317 - accuracy: 0.4336 - val_loss: 1.5308 - val_accuracy: 0.5625\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2735 - accuracy: 0.5508 - val_loss: 1.4250 - val_accuracy: 0.6250\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.1992 - accuracy: 0.5508 - val_loss: 1.3260 - val_accuracy: 0.5781\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1200 - accuracy: 0.6055 - val_loss: 1.2791 - val_accuracy: 0.6719\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.0399 - accuracy: 0.6133 - val_loss: 1.2006 - val_accuracy: 0.6250\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.8846 - accuracy: 0.6836 - val_loss: 1.1082 - val_accuracy: 0.7031\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.8702 - accuracy: 0.6719 - val_loss: 1.0477 - val_accuracy: 0.6875\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.8351 - accuracy: 0.7070 - val_loss: 1.0077 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7549 - accuracy: 0.6953 - val_loss: 0.9636 - val_accuracy: 0.6875\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6282 - accuracy: 0.7891 - val_loss: 0.9295 - val_accuracy: 0.6719\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.6352 - accuracy: 0.7578 - val_loss: 0.8676 - val_accuracy: 0.7031\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.5704 - accuracy: 0.7695 - val_loss: 0.8409 - val_accuracy: 0.7188\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4992 - accuracy: 0.8242 - val_loss: 0.8269 - val_accuracy: 0.7031\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4801 - accuracy: 0.8477 - val_loss: 0.8104 - val_accuracy: 0.7656\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4280 - accuracy: 0.8359 - val_loss: 0.7773 - val_accuracy: 0.7812\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4435 - accuracy: 0.8594 - val_loss: 0.7661 - val_accuracy: 0.7031\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.4198 - accuracy: 0.8398 - val_loss: 0.7980 - val_accuracy: 0.7188\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3540 - accuracy: 0.8867 - val_loss: 0.8154 - val_accuracy: 0.7344\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.3723 - accuracy: 0.8477 - val_loss: 0.8431 - val_accuracy: 0.6562\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2858 - accuracy: 0.9180 - val_loss: 0.9153 - val_accuracy: 0.6250\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3335 - accuracy: 0.8789 - val_loss: 0.7748 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170b9b460>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aeb8280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.9947 - accuracy: 0.7250 - 178ms/epoch - 59ms/step\n",
      "Test accuracy: 0.7250000238418579\n"
     ]
    }
   ],
   "source": [
    "#Testing our model's accuracy based on a separate test set. \"X and Y test\"\n",
    "test_loss, test_acc = model_mlp.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8483ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:27:33.884330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 22:27:33.886162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 22:27:33.887553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-17 22:27:34.113989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 22:27:34.115669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 22:27:34.117054: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 300)          2429400   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 200, 128)          219648    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 200, 128)          131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,913,248\n",
      "Trainable params: 2,913,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:27:34.348016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 22:27:34.349185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 22:27:34.350520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(128))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "009f3a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/5yx0jmr50jzfllwklwqq4mh00000gn/T/ipykernel_85677/2825685075.py:71: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gen_lyrics = df_gen_lyrics.append(generated_lyrics_list, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "generated_lyrics_dir = \"Generated Lyrics\"\n",
    "if not os.path.exists(generated_lyrics_dir):\n",
    "    os.makedirs(generated_lyrics_dir)\n",
    "\n",
    "generated_lyrics_list = []\n",
    "\n",
    "# Set the maximum number of words to generate for each artist\n",
    "max_words = max_lines * max_line_length\n",
    "\n",
    "# Iterate through each artist\n",
    "for artist in artists:\n",
    "    artist_str = str(artist)\n",
    "\n",
    "    # Generate 3 songs for the current artist\n",
    "    for _ in range(200):\n",
    "        # Filter the dataset for the current artist\n",
    "        artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "\n",
    "        # Concatenate all the lyrics of the artist\n",
    "        artist_lyrics = \" \".join(artist_data[\"Lyrics\"])\n",
    "\n",
    "        # Split the artist lyrics into words\n",
    "        artist_words = artist_lyrics.split()\n",
    "\n",
    "        # Shuffle the list of words\n",
    "        random.shuffle(artist_words)\n",
    "\n",
    "        # Generate lyrics line by line\n",
    "        lines_generated = 0\n",
    "        current_line = \"\"\n",
    "        generated_lyrics = \"\"\n",
    "        generated_lyrics_csv = \"\"\n",
    "\n",
    "        while lines_generated < max_lines and len(artist_words) > 0:\n",
    "            # Check if the current line plus the next word exceeds the maximum line length\n",
    "            if len(current_line.split()) >= max_line_length:\n",
    "                # Append the current line to the generated lyrics\n",
    "                generated_lyrics += current_line.strip() + \"\\n\"\n",
    "                generated_lyrics_csv += current_line.strip()\n",
    "                current_line = \"\"\n",
    "                lines_generated += 1\n",
    "\n",
    "            # Get the next word from the shuffled list\n",
    "            next_word = artist_words.pop(0)\n",
    "\n",
    "            # Truncate the word if it exceeds the maximum line length\n",
    "            if len(next_word) > max_line_length:\n",
    "                next_word = next_word[:max_line_length]\n",
    "\n",
    "            current_line += next_word + \" \"\n",
    "\n",
    "        # Append the last line to the generated lyrics\n",
    "        generated_lyrics += current_line.strip() + \"\\n\"\n",
    "        generated_lyrics_csv += current_line.strip()\n",
    "\n",
    "        generated_lyrics_list.append({\"Artist\": artist, \"Lyrics\": generated_lyrics_csv})\n",
    "\n",
    "        # Write the generated lyrics to a file for the current artist\n",
    "        artist_lyrics_dir = os.path.join(generated_lyrics_dir, artist_str)\n",
    "        if not os.path.exists(artist_lyrics_dir):\n",
    "            os.makedirs(artist_lyrics_dir)\n",
    "\n",
    "        file_name = os.path.join(artist_lyrics_dir, f\"generated_lyrics_{_ + 1}.txt\")\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(generated_lyrics)\n",
    "\n",
    "csv_file = os.path.join(generated_lyrics_dir, \"gen_lyrics.csv\")\n",
    "df_gen_lyrics = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "df_gen_lyrics = df_gen_lyrics.append(generated_lyrics_list, ignore_index=True)\n",
    "df_gen_lyrics.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 3ms/step\n",
      "0.895625\n"
     ]
    }
   ],
   "source": [
    "gen_lyrics = pd.read_csv('Generated Lyrics/gen_lyrics.csv')\n",
    "X_gen = gen_lyrics[\"Lyrics\"]\n",
    "X_gen_sequences = tokenizer.texts_to_sequences(X_gen)\n",
    "\n",
    "# Pad the sequences to have consistent length\n",
    "X_gen_padded = pad_sequences(X_gen_sequences, maxlen=max_words)\n",
    "\n",
    "# Make predictions on the generated lyrics\n",
    "predictions = model_mlp.predict(X_gen_padded)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the ground truth labels for the generated lyrics\n",
    "ground_truth_labels = label_encoder.transform(gen_lyrics[\"Artist\"])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_labels == ground_truth_labels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2e065e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_lyrics_dir = \"Generated Lyrics\"\n",
    "completed_songs_dir = \"Completed Songs\"\n",
    "\n",
    "# Iterate through each artist in the generated lyrics directory\n",
    "for artist in os.listdir(generated_lyrics_dir):\n",
    "    artist_dir = os.path.join(generated_lyrics_dir, str(artist))\n",
    "    completed_artist_dir = os.path.join(completed_songs_dir, artist)\n",
    "    \n",
    "    # Create a new directory for the completed songs for the current artist\n",
    "    if not os.path.exists(completed_artist_dir):\n",
    "        os.makedirs(completed_artist_dir)\n",
    "    \n",
    "    # Skip if the current entry is not a directory\n",
    "    if not os.path.isdir(artist_dir):\n",
    "        continue\n",
    "    \n",
    "    # Iterate through each song in the artist's directory\n",
    "    for song_file in os.listdir(artist_dir):\n",
    "        song_path = os.path.join(artist_dir, song_file)\n",
    "        \n",
    "        # Skip if the current entry is not a file or is the CSV file\n",
    "        if not os.path.isfile(song_path) or song_file == \"gen_lyrics.csv\":\n",
    "            continue\n",
    "        \n",
    "        completed_song_path = os.path.join(completed_artist_dir, song_file)\n",
    "        \n",
    "        # Read the generated song lyrics from the file\n",
    "        with open(song_path, \"r\") as f:\n",
    "            generated_lyrics = f.read()\n",
    "        \n",
    "        # Reverse the pre-processing steps\n",
    "        words = generated_lyrics.split()\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        filtered_words = [word for word in stemmed_words if word.isalpha() and word not in stop_words]\n",
    "        \n",
    "        # Create song lines based on maximum line length\n",
    "        lines_generated = 0\n",
    "        current_line = \"\"\n",
    "        song_lines = []\n",
    "        \n",
    "        for word in filtered_words:\n",
    "            if len(current_line.split()) >= max_line_length:\n",
    "                song_lines.append(current_line.strip())\n",
    "                current_line = \"\"\n",
    "                lines_generated += 1\n",
    "            \n",
    "            if len(word) > max_line_length:\n",
    "                word = word[:max_line_length]\n",
    "            \n",
    "            current_line += word + \" \"\n",
    "        \n",
    "        if current_line.strip():\n",
    "            song_lines.append(current_line.strip())\n",
    "        \n",
    "        # Write the original song lines to the completed song file\n",
    "        with open(completed_song_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(song_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "842c044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "del model_mlp\n",
    "del model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcae94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a56ab0802a9f8dff423d90067d6d7134d68682fb43c017439decf42f84c36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
