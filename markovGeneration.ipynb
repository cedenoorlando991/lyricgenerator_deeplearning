{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "lyric_gen_data = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "\n",
    "# Iterate over each unique artist in the dataset\n",
    "for artist_name in lyric_gen_data[\"Artist\"].unique():\n",
    "\n",
    "    # Get the lyrics for the current artist\n",
    "    artist_lyrics = lyric_gen_data.loc[lyric_gen_data[\"Artist\"] == artist_name, \"Lyrics\"].tolist()\n",
    "    tokenized_lyrics = [lyric.split() for lyric in artist_lyrics]\n",
    "\n",
    "    # Create a dictionary of word tuples and following words\n",
    "    word_dict = {}\n",
    "    for lyric in tokenized_lyrics:\n",
    "        for i in range(len(lyric) - 2):\n",
    "            word_tuple = tuple(lyric[i:i+2])\n",
    "            following_word = lyric[i+2]\n",
    "            if word_tuple not in word_dict:\n",
    "                word_dict[word_tuple] = []\n",
    "            word_dict[word_tuple].append(following_word)\n",
    "\n",
    "    # Create a list of starting tuples\n",
    "    starting_tuples = []\n",
    "    for lyric in tokenized_lyrics:\n",
    "        if len(lyric) >= 2:\n",
    "            starting_tuples.append((lyric[0], lyric[1]))\n",
    "\n",
    "    # Set the maximum number of lines and line length for the song\n",
    "    max_lines = 20\n",
    "    max_line_length = 10\n",
    "\n",
    "    # Create a folder for the generated lyrics for the specific artist\n",
    "    generated_lyrics_dir = \"generated Lyrics\"\n",
    "    artist_dir = os.path.join(generated_lyrics_dir, artist_name)\n",
    "    if not os.path.exists(artist_dir):\n",
    "        os.mkdir(artist_dir)\n",
    "\n",
    "    # Select a random starting tuple from the word dictionary\n",
    "    current_tuple = random.choice(starting_tuples)\n",
    "\n",
    "    # Generate multiple lines of lyrics\n",
    "    song_lines = []\n",
    "    for i in range(max_lines):\n",
    "        # Generate a new line of lyrics\n",
    "        new_line = list(current_tuple)\n",
    "        while len(new_line) < max_line_length:\n",
    "            if current_tuple in word_dict:\n",
    "                following_words = word_dict[current_tuple]\n",
    "                next_word = random.choice(following_words)\n",
    "                new_line.append(next_word)\n",
    "                current_tuple = (current_tuple[1], next_word)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # Convert the new line to a string\n",
    "        new_line_str = \" \".join(new_line)\n",
    "\n",
    "        # Check if the new line has already been generated\n",
    "        if new_line_str in song_lines:\n",
    "            break\n",
    "\n",
    "        # Append the new line to the song and the list of generated lines\n",
    "        song_lines.append(new_line_str)\n",
    "\n",
    "    # Combine the song lines into a single song string\n",
    "    song = \"\\n\".join(song_lines)\n",
    "\n",
    "    # Write the generated song to a file\n",
    "    filename = os.path.join(artist_dir, \"generated_song.txt\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Loop through the generated lyrics and predict the artist for each song\n",
    "for artist_name in os.listdir(\"generated lyrics\"):\n",
    "    artist_dir = os.path.join(\"generated lyrics\", artist_name)\n",
    "    if os.path.isdir(artist_dir):\n",
    "        all_lyrics = ''  # create an empty string to store all lyrics for an artist\n",
    "        for filename in os.listdir(artist_dir):\n",
    "            file_path = os.path.join(artist_dir, filename)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                generated_lyrics = f.read().replace('\\n', '') # remove new line character\n",
    "                all_lyrics += generated_lyrics\n",
    "                lyric_sequences = tokenizer.texts_to_sequences(all_lyrics)\n",
    "                lyrics = pad_sequences(lyric_sequences, maxlen=200)\n",
    "                y_pred_prob = model_mlp.predict(X_test)\n",
    "                predictions = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "pre_processed_data2 = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "artists2 = pre_processed_data2[\"Artist\"].unique()\n",
    "print(artists2)\n",
    "label_encoder2 = LabelEncoder()\n",
    "# pre_processed_data2[\"Artist\"] = label_encoder2.fit_transform(pre_processed_data2[\"Artist\"])\n",
    "# print(pre_processed_data2[\"Artist\"])\n",
    "# encoded_artist = 2\n",
    "# artist_name = label_encoder.inverse_transform([encoded_artist])[0]\n",
    "# print(artist_name)\n",
    "\n",
    "\n",
    "#Future thoughts, I could set up the generated songs and lyrics in a similar fashion to the classification model. So it would be in a \n",
    "# csv format, properly processed, and it would allow for easier predictions. I would have it produce 10 songs for each artist."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
