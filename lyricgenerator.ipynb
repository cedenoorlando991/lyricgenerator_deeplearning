{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665f422c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ba9afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory where the text files are located\n",
    "songs_dir = \"songs\"\n",
    "data = []\n",
    "# Loop through each file in the directory\n",
    "for root, dirs, files in os.walk(songs_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            artist = os.path.basename(root)\n",
    "            with open(os.path.join(root, file), 'r', encoding=\"utf8\") as f:\n",
    "                lyrics = f.read().replace('\\n', ' ')\n",
    "                # Add the data to the DataFrame\n",
    "                data.append([artist, lyrics])\n",
    "                \n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(data, columns=['Artist', 'Lyrics'])\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('lyrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6965f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"lyrics.csv\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create a list of stopwords to remove\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\"verse\")\n",
    "stop_words.add(\"intro\")\n",
    "\n",
    "# Create a stemmer to use for word stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess each lyric in the DataFrame\n",
    "for i, row in data.iterrows():\n",
    "#Convert the lyric to lowercase\n",
    "    lyric = str(row[\"Lyrics\"]).lower()\n",
    "    \n",
    "    split_lyric = lyric.split(\" lyrics[\", 1)\n",
    "    \n",
    "    # Check if the split was successful\n",
    "    if len(split_lyric) > 1:\n",
    "        # If successful, take the second part of the split\n",
    "        cleaned_lyric = split_lyric[1]\n",
    "    else:\n",
    "        # If not successful, take the original lyric\n",
    "        cleaned_lyric = lyric\n",
    "\n",
    "    #Tokenize the lyric into words\n",
    "    words = word_tokenize(cleaned_lyric)\n",
    "\n",
    "    #Remove stop words and punctuation\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    #Stem each word\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    #Join the stemmed words back into a single string\n",
    "    preprocessed_lyric = \" \".join(stemmed_words)\n",
    "\n",
    "    #Replace the original lyric with the preprocessed lyric in the DataFrame\n",
    "    data.at[i, \"Lyrics\"] = preprocessed_lyric\n",
    "\n",
    "# Export the preprocessed DataFrame to a CSV file\n",
    "data.to_csv(\"preprocessed_lyrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ab54ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "data = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"Lyrics\"])\n",
    "sequences = tokenizer.texts_to_sequences(data[\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e5abb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "artists = data[\"Artist\"].unique()\n",
    "# Encode the artist names as integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Artist\"] = label_encoder.fit_transform(data[\"Artist\"])\n",
    "\n",
    "# Initialize empty dataframes for training, validation, and testing\n",
    "train_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "val_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "test_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "\n",
    "for artist in artists:\n",
    "    # Get the data for the current artist\n",
    "    artist_data = data[data[\"Artist\"] == artist]\n",
    "    \n",
    "    # Split the artist data into training, validation, and testing sets\n",
    "    artist_train, artist_test = train_test_split(artist_data, test_size=0.2, random_state=42)\n",
    "    artist_train, artist_val = train_test_split(artist_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Concatenate the artist training, validation, and testing dataframes with the overall training, validation, and testing dataframes\n",
    "    train_df = pd.concat([train_df, artist_train])\n",
    "    val_df = pd.concat([val_df, artist_val])\n",
    "    test_df = pd.concat([test_df, artist_test])\n",
    "\n",
    "# Create a directory to store the CSV files\n",
    "directory = \"data_splits\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7de02e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train = pd.read_csv('data_splits/train.csv')\n",
    "val = pd.read_csv('data_splits/val.csv')\n",
    "test = pd.read_csv('data_splits/test.csv')\n",
    "\n",
    "#Train a Word2Vec model on the preprocessed lyrics data:\n",
    "sentences = [row.split() for row in train['Lyrics']]\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "#Creation of MLP model:\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=100))\n",
    "model_mlp.add(GlobalMaxPooling1D())\n",
    "model_mlp.add(Dense(100, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(8, activation='softmax'))\n",
    "\n",
    "tokenizer.fit_on_texts(train['Lyrics'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train['Lyrics'])\n",
    "sequences_val = tokenizer.texts_to_sequences(val['Lyrics'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test['Lyrics'])\n",
    "word_index = tokenizer.word_index\n",
    "X_train = pad_sequences(sequences_train, maxlen=100)\n",
    "X_val = pad_sequences(sequences_val, maxlen=100)\n",
    "X_test = pad_sequences(sequences_test, maxlen=100)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(train['Artist'])\n",
    "y_val = to_categorical(val['Artist'])\n",
    "y_test = to_categorical(test['Artist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f076bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=2623, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7e35714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0836 - accuracy: 0.0833 - val_loss: 2.0798 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0803 - accuracy: 0.1250 - val_loss: 2.0794 - val_accuracy: 0.1250\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0741 - accuracy: 0.1875 - val_loss: 2.0792 - val_accuracy: 0.1250\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 2.0866 - accuracy: 0.1667 - val_loss: 2.0791 - val_accuracy: 0.1250\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.0825 - accuracy: 0.1458 - val_loss: 2.0790 - val_accuracy: 0.1250\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0759 - accuracy: 0.1875 - val_loss: 2.0790 - val_accuracy: 0.1250\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.0712 - accuracy: 0.0833 - val_loss: 2.0790 - val_accuracy: 0.1250\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0746 - accuracy: 0.1458 - val_loss: 2.0788 - val_accuracy: 0.1250\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0734 - accuracy: 0.1667 - val_loss: 2.0788 - val_accuracy: 0.1250\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0735 - accuracy: 0.1667 - val_loss: 2.0787 - val_accuracy: 0.1250\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0817 - accuracy: 0.1250 - val_loss: 2.0786 - val_accuracy: 0.1250\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0783 - accuracy: 0.1667 - val_loss: 2.0786 - val_accuracy: 0.1250\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0691 - accuracy: 0.2292 - val_loss: 2.0784 - val_accuracy: 0.1250\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.0778 - accuracy: 0.1875 - val_loss: 2.0783 - val_accuracy: 0.1250\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0822 - accuracy: 0.0833 - val_loss: 2.0782 - val_accuracy: 0.1250\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.0681 - accuracy: 0.1042 - val_loss: 2.0781 - val_accuracy: 0.1250\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.0658 - accuracy: 0.1042 - val_loss: 2.0779 - val_accuracy: 0.1250\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0711 - accuracy: 0.2083 - val_loss: 2.0778 - val_accuracy: 0.1250\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0684 - accuracy: 0.1875 - val_loss: 2.0776 - val_accuracy: 0.1250\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0713 - accuracy: 0.1042 - val_loss: 2.0773 - val_accuracy: 0.1250\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0707 - accuracy: 0.1667 - val_loss: 2.0771 - val_accuracy: 0.1250\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0655 - accuracy: 0.2083 - val_loss: 2.0769 - val_accuracy: 0.1250\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0633 - accuracy: 0.1667 - val_loss: 2.0767 - val_accuracy: 0.1250\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0680 - accuracy: 0.1458 - val_loss: 2.0764 - val_accuracy: 0.1250\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0629 - accuracy: 0.1875 - val_loss: 2.0762 - val_accuracy: 0.1250\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0537 - accuracy: 0.2083 - val_loss: 2.0758 - val_accuracy: 0.1250\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0637 - accuracy: 0.2500 - val_loss: 2.0754 - val_accuracy: 0.1875\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0602 - accuracy: 0.1458 - val_loss: 2.0751 - val_accuracy: 0.2500\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0639 - accuracy: 0.2083 - val_loss: 2.0748 - val_accuracy: 0.2500\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0710 - accuracy: 0.1667 - val_loss: 2.0745 - val_accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0499 - accuracy: 0.2500 - val_loss: 2.0742 - val_accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0398 - accuracy: 0.2083 - val_loss: 2.0738 - val_accuracy: 0.1875\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0457 - accuracy: 0.2708 - val_loss: 2.0732 - val_accuracy: 0.1250\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0579 - accuracy: 0.1250 - val_loss: 2.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0274 - accuracy: 0.2708 - val_loss: 2.0721 - val_accuracy: 0.1875\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0406 - accuracy: 0.2500 - val_loss: 2.0716 - val_accuracy: 0.1875\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.0395 - accuracy: 0.2500 - val_loss: 2.0711 - val_accuracy: 0.1875\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0505 - accuracy: 0.1875 - val_loss: 2.0706 - val_accuracy: 0.1875\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0290 - accuracy: 0.2708 - val_loss: 2.0700 - val_accuracy: 0.1875\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0327 - accuracy: 0.3333 - val_loss: 2.0692 - val_accuracy: 0.1250\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0436 - accuracy: 0.2917 - val_loss: 2.0685 - val_accuracy: 0.0625\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0062 - accuracy: 0.3542 - val_loss: 2.0677 - val_accuracy: 0.0625\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0151 - accuracy: 0.2083 - val_loss: 2.0666 - val_accuracy: 0.1250\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0228 - accuracy: 0.2917 - val_loss: 2.0654 - val_accuracy: 0.1250\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9971 - accuracy: 0.3750 - val_loss: 2.0640 - val_accuracy: 0.1875\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0032 - accuracy: 0.2917 - val_loss: 2.0627 - val_accuracy: 0.1875\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9901 - accuracy: 0.3542 - val_loss: 2.0611 - val_accuracy: 0.1875\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9776 - accuracy: 0.3333 - val_loss: 2.0595 - val_accuracy: 0.1875\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9849 - accuracy: 0.3958 - val_loss: 2.0576 - val_accuracy: 0.1875\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9743 - accuracy: 0.3542 - val_loss: 2.0553 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ec1ba90>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aeb8280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 2.0728 - accuracy: 0.1875 - 31ms/epoch - 31ms/step\n",
      "Test accuracy: 0.1875\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_mlp.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1b89ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "del model_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2f17d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a56ab0802a9f8dff423d90067d6d7134d68682fb43c017439decf42f84c36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
