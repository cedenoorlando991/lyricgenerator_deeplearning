{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665f422c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ba9afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory where the text files are located\n",
    "songs_dir = \"songs\"\n",
    "data = []\n",
    "# Loop through each file in the directory\n",
    "for root, dirs, files in os.walk(songs_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            artist = os.path.basename(root)\n",
    "            with open(os.path.join(root, file), 'r', encoding=\"utf8\") as f:\n",
    "                lyrics = f.read().replace('\\n', ' ')\n",
    "                # Add the data to the DataFrame\n",
    "                data.append([artist, lyrics])\n",
    "                \n",
    "# Create an empty DataFrame to store the data\n",
    "df = pd.DataFrame(data, columns=['Artist', 'Lyrics'])\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('lyrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6965f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jarraomar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(\"lyrics.csv\")\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create a list of stopwords to remove\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.add(\"verse\")\n",
    "stop_words.add(\"intro\")\n",
    "\n",
    "# Create a stemmer to use for word stemming\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocess each lyric in the DataFrame\n",
    "for i, row in data.iterrows():\n",
    "#Convert the lyric to lowercase\n",
    "    lyric = str(row[\"Lyrics\"]).lower()\n",
    "    match = re.search(r'lyrics\\[[^\\]]*\\]', lyric)\n",
    "\n",
    "    # Check if the split was successful\n",
    "    if match:\n",
    "        split_index = match.end()\n",
    "        cleaned_lyric = lyric[split_index:]\n",
    "    else:\n",
    "        cleaned_lyric = lyric\n",
    "\n",
    "    #Tokenize the lyric into words\n",
    "    words = word_tokenize(cleaned_lyric)\n",
    "\n",
    "    #Remove stop words and punctuation\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    #Stem each word\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    #Join the stemmed words back into a single string\n",
    "    preprocessed_lyric = \" \".join(stemmed_words)\n",
    "\n",
    "    #Replace the original lyric with the preprocessed lyric in the DataFrame\n",
    "    data.at[i, \"Lyrics\"] = preprocessed_lyric\n",
    "\n",
    "# Export the preprocessed DataFrame to a CSV file\n",
    "data.to_csv(\"preprocessed_lyrics.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ab54ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "pre_processed_data = pd.read_csv(\"preprocessed_lyrics.csv\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(pre_processed_data[\"Lyrics\"])\n",
    "sequences = tokenizer.texts_to_sequences(pre_processed_data[\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3e5abb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#For Artist Classification\n",
    "\n",
    "artists = pre_processed_data[\"Artist\"].unique()\n",
    "# Encode the artist names as integer labels\n",
    "label_encoder = LabelEncoder()\n",
    "pre_processed_data[\"Artist\"] = label_encoder.fit_transform(pre_processed_data[\"Artist\"])\n",
    "\n",
    "# Initialize empty dataframes for training, validation, and testing\n",
    "train_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "val_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "test_df = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "\n",
    "for artist in artists:\n",
    "    # Get the data for the current artist\n",
    "    artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "    \n",
    "    # Split the artist data into training, validation, and testing sets\n",
    "    artist_train, artist_test = train_test_split(artist_data, test_size=0.2, random_state=42)\n",
    "    artist_train, artist_val = train_test_split(artist_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Concatenate the artist training, validation, and testing dataframes with the overall training, validation, and testing dataframes\n",
    "    train_df = pd.concat([train_df, artist_train])\n",
    "    val_df = pd.concat([val_df, artist_val])\n",
    "    test_df = pd.concat([test_df, artist_test])\n",
    "\n",
    "# Create a directory to store the CSV files\n",
    "directory = \"data_splits\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "    val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "    test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n",
    "\n",
    "train_df.to_csv(os.path.join(directory, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(directory, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(directory, \"test.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7de02e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train = pd.read_csv('data_splits/train.csv')\n",
    "val = pd.read_csv('data_splits/val.csv')\n",
    "test = pd.read_csv('data_splits/test.csv')\n",
    "\n",
    "#Creation of MLP model:\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_mlp.add(GlobalMaxPooling1D())\n",
    "model_mlp.add(Dense(100, activation='relu'))\n",
    "model_mlp.add(Dropout(0.4))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(128, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "model_mlp.add(Dense(8, activation='softmax'))\n",
    "\n",
    "tokenizer.fit_on_texts(train['Lyrics'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train['Lyrics'])\n",
    "sequences_val = tokenizer.texts_to_sequences(val['Lyrics'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test['Lyrics'])\n",
    "word_index = tokenizer.word_index\n",
    "X_train = pad_sequences(sequences_train, maxlen=200)\n",
    "X_val = pad_sequences(sequences_val, maxlen=200)\n",
    "X_test = pad_sequences(sequences_test, maxlen=200)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y_train = to_categorical(train['Artist'])\n",
    "y_val = to_categorical(val['Artist'])\n",
    "y_test = to_categorical(test['Artist'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f076bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply earlystopping in order to avoid over-fitting\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_mlp.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e35714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 3s 132ms/step - loss: 2.0747 - accuracy: 0.1523 - val_loss: 2.0801 - val_accuracy: 0.1250\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.0937 - accuracy: 0.1250 - val_loss: 2.0799 - val_accuracy: 0.1250\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.0865 - accuracy: 0.1250 - val_loss: 2.0796 - val_accuracy: 0.1250\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.0766 - accuracy: 0.1250 - val_loss: 2.0790 - val_accuracy: 0.1250\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0815 - accuracy: 0.1211 - val_loss: 2.0786 - val_accuracy: 0.1562\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0741 - accuracy: 0.1523 - val_loss: 2.0785 - val_accuracy: 0.1250\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0772 - accuracy: 0.1523 - val_loss: 2.0783 - val_accuracy: 0.1250\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0826 - accuracy: 0.0898 - val_loss: 2.0778 - val_accuracy: 0.1406\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0798 - accuracy: 0.1094 - val_loss: 2.0774 - val_accuracy: 0.1250\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.0722 - accuracy: 0.1367 - val_loss: 2.0771 - val_accuracy: 0.1250\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0701 - accuracy: 0.1992 - val_loss: 2.0769 - val_accuracy: 0.1250\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.0711 - accuracy: 0.1445 - val_loss: 2.0764 - val_accuracy: 0.1250\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0790 - accuracy: 0.1328 - val_loss: 2.0751 - val_accuracy: 0.1250\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 2.0692 - accuracy: 0.1719 - val_loss: 2.0738 - val_accuracy: 0.2188\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0765 - accuracy: 0.1289 - val_loss: 2.0722 - val_accuracy: 0.2344\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0730 - accuracy: 0.1484 - val_loss: 2.0711 - val_accuracy: 0.2031\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.0593 - accuracy: 0.1992 - val_loss: 2.0705 - val_accuracy: 0.1406\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.0594 - accuracy: 0.1953 - val_loss: 2.0681 - val_accuracy: 0.3594\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 2.0634 - accuracy: 0.1797 - val_loss: 2.0648 - val_accuracy: 0.3125\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0391 - accuracy: 0.2422 - val_loss: 2.0613 - val_accuracy: 0.1250\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.0551 - accuracy: 0.1602 - val_loss: 2.0574 - val_accuracy: 0.1562\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.0266 - accuracy: 0.2148 - val_loss: 2.0516 - val_accuracy: 0.1250\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.0167 - accuracy: 0.2422 - val_loss: 2.0432 - val_accuracy: 0.2031\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.0007 - accuracy: 0.2539 - val_loss: 2.0330 - val_accuracy: 0.1719\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.9990 - accuracy: 0.2656 - val_loss: 2.0171 - val_accuracy: 0.1562\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9593 - accuracy: 0.2852 - val_loss: 1.9972 - val_accuracy: 0.1562\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.9287 - accuracy: 0.3477 - val_loss: 1.9690 - val_accuracy: 0.2031\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.8548 - accuracy: 0.4766 - val_loss: 1.9241 - val_accuracy: 0.4844\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1.7798 - accuracy: 0.4492 - val_loss: 1.8703 - val_accuracy: 0.4219\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.7061 - accuracy: 0.4805 - val_loss: 1.8049 - val_accuracy: 0.3906\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.6305 - accuracy: 0.4375 - val_loss: 1.7217 - val_accuracy: 0.6094\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5288 - accuracy: 0.5117 - val_loss: 1.6407 - val_accuracy: 0.5938\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.4415 - accuracy: 0.5156 - val_loss: 1.5632 - val_accuracy: 0.5781\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.3071 - accuracy: 0.6211 - val_loss: 1.4767 - val_accuracy: 0.6562\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.2194 - accuracy: 0.6055 - val_loss: 1.4244 - val_accuracy: 0.6406\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.0693 - accuracy: 0.6641 - val_loss: 1.3249 - val_accuracy: 0.6719\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.9519 - accuracy: 0.7188 - val_loss: 1.3593 - val_accuracy: 0.5312\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.8097 - accuracy: 0.7500 - val_loss: 1.1968 - val_accuracy: 0.5938\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7398 - accuracy: 0.7773 - val_loss: 1.1157 - val_accuracy: 0.6406\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.6952 - accuracy: 0.7656 - val_loss: 1.0850 - val_accuracy: 0.6875\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6273 - accuracy: 0.7812 - val_loss: 1.0222 - val_accuracy: 0.6250\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5567 - accuracy: 0.8477 - val_loss: 1.0196 - val_accuracy: 0.6250\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4215 - accuracy: 0.9141 - val_loss: 0.9222 - val_accuracy: 0.7031\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3892 - accuracy: 0.8672 - val_loss: 0.9092 - val_accuracy: 0.7188\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4196 - accuracy: 0.8516 - val_loss: 0.9168 - val_accuracy: 0.6250\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.9023 - val_loss: 0.8900 - val_accuracy: 0.6875\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2832 - accuracy: 0.9258 - val_loss: 0.8802 - val_accuracy: 0.6562\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2637 - accuracy: 0.9180 - val_loss: 0.8844 - val_accuracy: 0.6875\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2252 - accuracy: 0.9453 - val_loss: 0.8736 - val_accuracy: 0.7031\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2117 - accuracy: 0.9414 - val_loss: 0.8644 - val_accuracy: 0.7031\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2488 - accuracy: 0.9102 - val_loss: 0.8799 - val_accuracy: 0.7031\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1955 - accuracy: 0.9375 - val_loss: 0.8351 - val_accuracy: 0.7188\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2294 - accuracy: 0.9258 - val_loss: 0.8451 - val_accuracy: 0.7188\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1565 - accuracy: 0.9688 - val_loss: 0.8385 - val_accuracy: 0.6875\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.1611 - accuracy: 0.9531 - val_loss: 0.8384 - val_accuracy: 0.6719\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1380 - accuracy: 0.9727 - val_loss: 0.8533 - val_accuracy: 0.6719\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1058 - accuracy: 0.9766 - val_loss: 0.8693 - val_accuracy: 0.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169a918b0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aeb8280d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 0.7986 - accuracy: 0.7500 - 185ms/epoch - 62ms/step\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Testing our model's accuracy based on a separate test set. \"X and Y test\"\n",
    "test_loss, test_acc = model_mlp.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8483ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 13:51:43.356622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 13:51:43.359248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 13:51:43.360789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-17 13:51:43.556925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 13:51:43.558334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 13:51:43.560190: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 200, 300)          2429400   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 128)          219648    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 200, 128)          131584    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 200, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,913,248\n",
      "Trainable params: 2,913,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 13:51:43.909493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-17 13:51:43.915431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-17 13:51:43.920114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=200))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(128))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "009f3a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/5yx0jmr50jzfllwklwqq4mh00000gn/T/ipykernel_85677/2878132248.py:71: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_gen_lyrics = df_gen_lyrics.append(generated_lyrics_list, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "generated_lyrics_dir = \"Generated Lyrics\"\n",
    "if not os.path.exists(generated_lyrics_dir):\n",
    "    os.makedirs(generated_lyrics_dir)\n",
    "\n",
    "generated_lyrics_list = []\n",
    "\n",
    "# Set the maximum number of words to generate for each artist\n",
    "max_words = max_lines * max_line_length\n",
    "\n",
    "# Iterate through each artist\n",
    "for artist in artists:\n",
    "    artist_str = str(artist)\n",
    "\n",
    "    # Generate 3 songs for the current artist\n",
    "    for _ in range(50):\n",
    "        # Filter the dataset for the current artist\n",
    "        artist_data = pre_processed_data[pre_processed_data[\"Artist\"] == artist]\n",
    "\n",
    "        # Concatenate all the lyrics of the artist\n",
    "        artist_lyrics = \" \".join(artist_data[\"Lyrics\"])\n",
    "\n",
    "        # Split the artist lyrics into words\n",
    "        artist_words = artist_lyrics.split()\n",
    "\n",
    "        # Shuffle the list of words\n",
    "        random.shuffle(artist_words)\n",
    "\n",
    "        # Generate lyrics line by line\n",
    "        lines_generated = 0\n",
    "        current_line = \"\"\n",
    "        generated_lyrics = \"\"\n",
    "        generated_lyrics_csv = \"\"\n",
    "\n",
    "        while lines_generated < max_lines and len(artist_words) > 0:\n",
    "            # Check if the current line plus the next word exceeds the maximum line length\n",
    "            if len(current_line.split()) >= max_line_length:\n",
    "                # Append the current line to the generated lyrics\n",
    "                generated_lyrics += current_line.strip() + \"\\n\"\n",
    "                generated_lyrics_csv += current_line.strip()\n",
    "                current_line = \"\"\n",
    "                lines_generated += 1\n",
    "\n",
    "            # Get the next word from the shuffled list\n",
    "            next_word = artist_words.pop(0)\n",
    "\n",
    "            # Truncate the word if it exceeds the maximum line length\n",
    "            if len(next_word) > max_line_length:\n",
    "                next_word = next_word[:max_line_length]\n",
    "\n",
    "            current_line += next_word + \" \"\n",
    "\n",
    "        # Append the last line to the generated lyrics\n",
    "        generated_lyrics += current_line.strip() + \"\\n\"\n",
    "        generated_lyrics_csv += current_line.strip()\n",
    "\n",
    "        generated_lyrics_list.append({\"Artist\": artist, \"Lyrics\": generated_lyrics_csv})\n",
    "\n",
    "        # Write the generated lyrics to a file for the current artist\n",
    "        artist_lyrics_dir = os.path.join(generated_lyrics_dir, artist_str)\n",
    "        if not os.path.exists(artist_lyrics_dir):\n",
    "            os.makedirs(artist_lyrics_dir)\n",
    "\n",
    "        file_name = os.path.join(artist_lyrics_dir, f\"generated_lyrics_{_ + 1}.txt\")\n",
    "        with open(file_name, \"w\") as f:\n",
    "            f.write(generated_lyrics)\n",
    "\n",
    "csv_file = os.path.join(generated_lyrics_dir, \"gen_lyrics.csv\")\n",
    "df_gen_lyrics = pd.DataFrame(columns=[\"Artist\", \"Lyrics\"])\n",
    "df_gen_lyrics = df_gen_lyrics.append(generated_lyrics_list, ignore_index=True)\n",
    "df_gen_lyrics.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "gen_lyrics = pd.read_csv('Generated Lyrics/gen_lyrics.csv')\n",
    "X_gen = gen_lyrics[\"Lyrics\"]\n",
    "X_gen_sequences = tokenizer.texts_to_sequences(X_gen)\n",
    "\n",
    "# Pad the sequences to have consistent length\n",
    "X_gen_padded = pad_sequences(X_gen_sequences, maxlen=max_words)\n",
    "\n",
    "# Make predictions on the generated lyrics\n",
    "predictions = model_mlp.predict(X_gen_padded)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the ground truth labels for the generated lyrics\n",
    "ground_truth_labels = label_encoder.transform(gen_lyrics[\"Artist\"])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_labels == ground_truth_labels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "842c044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "del model_mlp\n",
    "del model_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcae94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a56ab0802a9f8dff423d90067d6d7134d68682fb43c017439decf42f84c36d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
